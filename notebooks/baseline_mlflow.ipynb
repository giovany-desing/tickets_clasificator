{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 16:54:00 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "\u001b[31m2025/05/20 16:54:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Importar infer_signature para la advertencia del modelo (si quieres añadirlo)\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- 1. Preparación de Datos (sin cambios) ---\n",
    "def preparar_datos(ruta_csv: str, x: str, y: str, test_size=0.3, random_state=42):\n",
    "    logging.info(f\"Cargando datos desde: {ruta_csv}\")\n",
    "    try:\n",
    "        df = pd.read_csv(ruta_csv)\n",
    "        logging.info(f\"Dataset cargado exitosamente. Columnas encontradas: {df.columns.tolist()}\")\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"ERROR: El archivo CSV no fue encontrado en la ruta: {ruta_csv}\")\n",
    "        return None, None, None, None, None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"ERROR al cargar el CSV: {e}\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    if x not in df.columns:\n",
    "        logging.error(f\"ERROR: La columna '{x}' no se encuentra en el CSV.\")\n",
    "        return None, None, None, None, None\n",
    "    if y not in df.columns:\n",
    "        logging.error(f\"ERROR: La columna '{y}' no se encuentra en el CSV.\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    logging.info(f\"Columna de texto seleccionada: '{x}'\")\n",
    "    logging.info(f\"Columna de etiqueta seleccionada: '{y}'\")\n",
    "\n",
    "    df[x] = df[x].astype(str).fillna('')\n",
    "    df[y] = df[y].astype('category').cat.codes\n",
    "\n",
    "    X_text = df[x]\n",
    "    y = df[y]\n",
    "\n",
    "    logging.info(f\"Número total de muestras: {len(df)}\")\n",
    "    logging.info(f\"Distribución de etiquetas:\\n{y.value_counts(normalize=True)}\")\n",
    "\n",
    "    X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "        X_text, y, test_size=test_size, random_state=random_state, stratify=y if y.nunique() > 1 else None\n",
    "    )\n",
    "\n",
    "    logging.info(f\"Muestras de entrenamiento: {len(X_train_text)}\")\n",
    "    logging.info(f\"Muestras de prueba: {len(X_test_text)}\")\n",
    "\n",
    "    logging.info(\"Vectorizando texto con TfidfVectorizer...\")\n",
    "    vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "    X_train_vect = vectorizer.fit_transform(X_train_text)\n",
    "    X_test_vect = vectorizer.transform(X_test_text)\n",
    "    logging.info(\"Vectorización completada.\")\n",
    "    logging.info(f\"Dimensiones de X_train_vect: {X_train_vect.shape}\")\n",
    "    logging.info(f\"Dimensiones de X_test_vect: {X_test_vect.shape}\")\n",
    "\n",
    "    return X_train_vect, X_test_vect, y_train, y_test, vectorizer\n",
    "\n",
    "# --- 2. Función para trackear el los experimentos, evaluar y registrar el Modelo ---\n",
    "def evaluar_y_registrar_modelo(model_name, model, X_train, y_train, X_test, y_test, params=None):\n",
    "    \"\"\"\n",
    "    Entrena, evalúa y registra un modelo con MLflow como una corrida anidada.\n",
    "    ASUME que ya hay una corrida padre activa.\n",
    "    \"\"\"\n",
    "    logging.info(f\"\\n--- Entrenando y evaluando: {model_name} ---\")\n",
    "\n",
    "    # ¡Importante! Aquí se inicia la corrida ANIDADA\n",
    "    with mlflow.start_run(run_name=model_name, nested=True) as run:\n",
    "        mlflow.set_tag(\"mlflow.runName\", model_name)\n",
    "        mlflow.set_tag(\"dataset\", \"Custom_Text_CSV\")\n",
    "        mlflow.set_tag(\"model_type\", \"text_classifier_baseline\")\n",
    "\n",
    "        if params:\n",
    "            mlflow.log_params(params)\n",
    "        else:\n",
    "            try:\n",
    "                mlflow.log_params(model.get_params())\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"No se pudieron registrar parámetros para {model_name}: {e}\")\n",
    "\n",
    "        start_time = pd.Timestamp.now()\n",
    "        model.fit(X_train, y_train)\n",
    "        end_time = pd.Timestamp.now()\n",
    "        training_time = (end_time - start_time).total_seconds()\n",
    "        logging.info(f\"Tiempo de entrenamiento: {training_time:.4f} segundos\")\n",
    "        mlflow.log_metric(\"training_time_seconds\", training_time)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Puedes añadir la lógica para predict_proba si la necesitas, como en tu script original\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            try:\n",
    "                y_pred_proba = model.predict_proba(X_test)\n",
    "                # Opcional: loguear predict_proba si es útil\n",
    "            except Exception as e_proba:\n",
    "                logging.warning(f\"No se pudo calcular predict_proba para {model_name}: {e_proba}\")\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        logging.info(f\"Accuracy: {accuracy:.4f}\")\n",
    "        logging.info(f\"Precision (weighted): {precision:.4f}\")\n",
    "        logging.info(f\"Recall (weighted): {recall:.4f}\")\n",
    "        logging.info(f\"F1-score (weighted): {f1:.4f}\")\n",
    "\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision_weighted\", precision)\n",
    "        mlflow.log_metric(\"recall_weighted\", recall)\n",
    "        mlflow.log_metric(\"f1_weighted\", f1)\n",
    "\n",
    "        precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        mlflow.log_metric(\"precision_macro\", precision_macro)\n",
    "        mlflow.log_metric(\"recall_macro\", recall_macro)\n",
    "        mlflow.log_metric(\"f1_macro\", f1_macro)\n",
    "\n",
    "        # --- Opcional: Añadir signature e input_example para evitar la advertencia ---\n",
    "        # Asegúrate de que X_test sea un numpy array para input_example\n",
    "        # Si X_test_vect es una matriz dispersa, convierte una fila a array denso\n",
    "        if hasattr(X_test, 'toarray'): # Si es una matriz dispersa de SciPy\n",
    "            input_example_data = X_test[0].toarray()\n",
    "        elif isinstance(X_test, pd.DataFrame):\n",
    "            input_example_data = X_test.iloc[0].values.reshape(1, -1) # Para DataFrames\n",
    "        else: # Asume numpy array u otro formato compatible\n",
    "            input_example_data = X_test[0].reshape(1, -1) if X_test.ndim == 1 else X_test[0]\n",
    "\n",
    "\n",
    "        signature = infer_signature(X_test, model.predict(X_test))\n",
    "\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model,\n",
    "            artifact_path=model_name.lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\"),\n",
    "            signature=signature,\n",
    "            input_example=input_example_data\n",
    "        )\n",
    "        logging.info(f\"Modelo {model_name} registrado en MLflow\")\n",
    "\n",
    "        run_id = run.info.run_id\n",
    "        logging.info(f\"MLflow Run ID para {model_name}: {run_id}\")\n",
    "\n",
    "    return model_name, accuracy, f1\n",
    "\n",
    "# --- 3. Definición del Experimento y Ejecución del Baseline ---\n",
    "def ejecutar_baseline_modelos(\n",
    "    ruta_csv_param: str,\n",
    "    columna_texto_param: str,\n",
    "    columna_etiqueta_param: str,\n",
    "    experiment_name=\"Baseline_Clasificacion_Texto\"\n",
    "):\n",
    "    \"\"\"Define y ejecuta el baseline para varios modelos usando un CSV de texto.\"\"\"\n",
    "\n",
    "    # 1. Configurar MLflow para usar un directorio local específico\n",
    "    # Asegúrate de que esta ruta exista o pueda ser creada por MLflow.\n",
    "    # Usaremos una ruta absoluta para evitar problemas de directorio de trabajo.\n",
    "    mlflow_tracking_path = \"/Users/davinci/Desktop/tickets_clasificator/mlflow_tracking_data\" # <-- CAMBIO CLAVE AQUÍ\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_path)\n",
    "    logging.info(f\"MLflow Tracking URI configurado a: {mlflow_tracking_path}\")\n",
    "\n",
    "\n",
    "    # 2. Configurar el experimento (lo crea si no existe, lo selecciona si existe)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    logging.info(f\"MLflow Experiment configurado a: {experiment_name}\")\n",
    "\n",
    "\n",
    "    with mlflow.start_run(run_name=\"Experimento\") as parent_run: # <-- Corrida Padre\n",
    "        logging.info(f\"Iniciando corrida padre para el experimento '{experiment_name}' (Run ID: {parent_run.info.run_id})\")\n",
    "\n",
    "        # Cargar y preparar datos\n",
    "        X_train_vect, X_test_vect, y_train, y_test, vectorizer = preparar_datos(\n",
    "            ruta_csv_param, columna_texto_param, columna_etiqueta_param\n",
    "        )\n",
    "\n",
    "        if X_train_vect is None:\n",
    "            logging.warning(\"No se pudieron cargar o procesar los datos. Abortando el baseline.\")\n",
    "            return\n",
    "\n",
    "        # Registrar el vectorizador de texto, es crucial para la reproducibilidad\n",
    "        if vectorizer:\n",
    "            mlflow.sklearn.log_model(vectorizer, \"tfidf_vectorizer\")\n",
    "            logging.info(\"TfidfVectorizer registrado en MLflow como artefacto de la corrida padre.\")\n",
    "\n",
    "\n",
    "        # Definición de modelos\n",
    "        models = {\n",
    "            \"Regresion Logistica\": LogisticRegression(solver='liblinear', random_state=42, class_weight='balanced'),\n",
    "            \"SVM (Kernel Lineal)\": SVC(kernel='linear', probability=True, random_state=42, class_weight='balanced'),\n",
    "            \"KNN (K-Nearest Neighbors)\": KNeighborsClassifier(n_neighbors=5),\n",
    "            \"Arbol de Decision\": DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "            \"Random Forest\": RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "            \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "            \"Naive Bayes Multinomial\": MultinomialNB()\n",
    "        }\n",
    "\n",
    "        resultados_baseline = []\n",
    "\n",
    "        # Bucle para evaluar cada modelo\n",
    "        for nombre, modelo_instancia in models.items():\n",
    "            # Cada llamada a evaluar_y_registrar_modelo ahora creará una corrida ANIDADA\n",
    "            nombre_modelo_res, acc_res, f1_res = evaluar_y_registrar_modelo(\n",
    "                nombre,\n",
    "                modelo_instancia,\n",
    "                X_train_vect, y_train, X_test_vect, y_test\n",
    "            )\n",
    "            resultados_baseline.append({\"modelo\": nombre_modelo_res, \"accuracy\": acc_res, \"f1_weighted\": f1_res})\n",
    "\n",
    "        logging.info(\"\\n--- Resumen del Baseline ---\")\n",
    "        if resultados_baseline:\n",
    "            df_resultados = pd.DataFrame(resultados_baseline)\n",
    "            logging.info(\"Resultados\")\n",
    "            logging.info(df_resultados.sort_values(by=\"f1_weighted\", ascending=False))\n",
    "\n",
    "            df_resultados.to_csv(\"baseline_results.csv\", index=False)\n",
    "            mlflow.log_artifact(\"baseline_results.csv\")\n",
    "            logging.info(\"Resultados del baseline guardados como artefacto.\")\n",
    "        else:\n",
    "            logging.warning(\"No se generaron resultados.\")\n",
    "\n",
    "        logging.info(f\"\\nRevisar la UI de MLflow (ejecutar en terminal 'mlflow ui --backend-store-uri {mlflow_tracking_path}') para ver los detalles de cada corrida.\")\n",
    "        logging.info(f\"En el experimento: {experiment_name}\")\n",
    "\n",
    "    logging.info(f\"Corrida baseline completada y cerrada.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    RUTA_A_TU_CSV = \"/Users/davinci/Desktop/tickets_clasificator/data_project/processed_data/tickets_inputs_eng_1.csv\"\n",
    "    NOMBRE_COLUMNA_TEXTO = \"close_notes_processed\"\n",
    "    NOMBRE_COLUMNA_ETIQUETA = \"tema_nombre\"\n",
    "\n",
    "    nombre_experimento_mlflow = \"Baseline_Clasificacion_tickets_ada\"\n",
    "\n",
    "    ejecutar_baseline_modelos(\n",
    "        RUTA_A_TU_CSV,\n",
    "        NOMBRE_COLUMNA_TEXTO,\n",
    "        NOMBRE_COLUMNA_ETIQUETA,\n",
    "        experiment_name=nombre_experimento_mlflow\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_model =logged_model = 'runs:/4deceb9849af48749ec68b873a05b7d6/regresion_logistica'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: regresion_logistica\n",
       "  flavor: mlflow.sklearn\n",
       "  run_id: 4deceb9849af48749ec68b873a05b7d6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargo el modelo\n",
    "lr_model = mlflow.sklearn.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 17:31:35 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/05/20 17:31:35 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
      "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "INFO  [alembic.runtime.migration] Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "INFO  [alembic.runtime.migration] Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "INFO  [alembic.runtime.migration] Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n"
     ]
    }
   ],
   "source": [
    "#conexion al cliente mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\"\n",
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs()\n",
    "# Extrae los IDs únicos de los experimentos que he realizado\n",
    "experiment_ids = runs['experiment_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['218802408105393737'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = client.search_runs(experiment_ids=[218802408105393737])\n",
    "for run in runs:\n",
    "    print(run.info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
